{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #Dataframe Manipulation library\n",
    "import numpy as np #Data Manipulation library\n",
    "from pathlib import Path\n",
    "\n",
    "#sklearn modules for Feature Extraction & Modelling\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "#Libraries for Plotting \n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "\n",
    "#Read files Iteratively\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from \u001b[1mbusiness\u001b[0m directory\n",
      "Loading data from \u001b[1mentertainment\u001b[0m directory\n",
      "Loading data from \u001b[1mpolitics\u001b[0m directory\n",
      "Loading data from \u001b[1msport\u001b[0m directory\n",
      "Loading data from \u001b[1mtech\u001b[0m directory\n",
      "\n",
      "Entire Data is loaded successfully\n"
     ]
    }
   ],
   "source": [
    "def load_data(folder_names, root_path):\n",
    "    fileNames = [path + \"./BBC News Summary/News Articles/\" + folder + '/' + \"*.txt\"\n",
    "        for path,folder in zip([root_path]*len(folder_names), folder_names)]\n",
    "\n",
    "    doc_list = []\n",
    "    tags = folder_names\n",
    "    for docs in fileNames:\n",
    "        #print(docs)\n",
    "        doc = glob.glob(docs)#glob method iterates through all files and reads the text in documents in the folders\n",
    "        for text in doc:\n",
    "            with open(text, encoding=\"latin-1\") as f:\n",
    "                topic = docs.split('/')[len(docs.split('/'))-2]\n",
    "                lines = f.readlines()\n",
    "                heading = lines[0].strip()#stripping the text by spaces and using first element into heading\n",
    "                body = ' '.join([l.strip() for l in lines[1:]])\n",
    "                doc_list.append([topic,heading,body])\n",
    "        print(f\"Loading data from \\033[1m{topic}\\033[0m directory\")\n",
    "    print(\"\\nEntire Data is loaded successfully\")\n",
    "    \n",
    "    return doc_list\n",
    "folder_names = ['business','entertainment','politics','sport','tech']\n",
    "docs = load_data(folder_names=folder_names,root_path=os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Heading</th>\n",
       "      <th>Article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>business</td>\n",
       "      <td>Ad sales boost Time Warner profit</td>\n",
       "      <td>Quarterly profits at US media giant TimeWarne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>Dollar gains on Greenspan speech</td>\n",
       "      <td>The dollar has hit its highest level against ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>business</td>\n",
       "      <td>Yukos unit buyer faces loan claim</td>\n",
       "      <td>The owners of embattled Russian oil giant Yuk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>business</td>\n",
       "      <td>High fuel prices hit BA's profits</td>\n",
       "      <td>British Airways has blamed high fuel prices f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>business</td>\n",
       "      <td>Pernod takeover talk lifts Domecq</td>\n",
       "      <td>Shares in UK drinks and food firm Allied Dome...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Category                            Heading  \\\n",
       "0  business  Ad sales boost Time Warner profit   \n",
       "1  business   Dollar gains on Greenspan speech   \n",
       "2  business  Yukos unit buyer faces loan claim   \n",
       "3  business  High fuel prices hit BA's profits   \n",
       "4  business  Pernod takeover talk lifts Domecq   \n",
       "\n",
       "                                             Article  \n",
       "0   Quarterly profits at US media giant TimeWarne...  \n",
       "1   The dollar has hit its highest level against ...  \n",
       "2   The owners of embattled Russian oil giant Yuk...  \n",
       "3   British Airways has blamed high fuel prices f...  \n",
       "4   Shares in UK drinks and food firm Allied Dome...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame(docs, columns = ['Category','Heading','Article'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words = 'english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the tfidf |matrix : (2225, 3623)\n",
      "There are 2225 number of News Articles having 3623 unique words in tfidf vectors\n"
     ]
    }
   ],
   "source": [
    "vectors = vectorizer.fit_transform(data[\"Heading\"].values) # .values: convert DataFrame columns into List.List of data will be transformed into tfidf vector\n",
    "print(f\"The shape of the tfidf |matrix : {vectors.shape}\")\n",
    "print(f\"There are {vectors.shape[0]} number of News Articles having {vectors.shape[1]} unique words in tfidf vectors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x3623 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 4 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_query = [\"Stock Market Rates are rising\"]\n",
    "new_query_vector = vectorizer.transform(new_query)\n",
    "new_query_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = cosine_similarity(X = vectors, Y = new_query_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       ...,\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 News Articles similar to new_query are : \n",
      "\n",
      "['Stock market eyes Japan recovery']\n",
      "['US interest rates increased to 2%']\n",
      "['French consumer spending rising']\n",
      "[\"Labour's core support takes stock\"]\n",
      "['Home loan approvals rising again']\n",
      "[\"Small firms 'hit by rising costs'\"]\n",
      "['UK interest rates held at 4.75%']\n",
      "['Australia rates at four year high']\n",
      "['Bank set to leave rates on hold']\n",
      "['Bank opts to leave rates on hold']\n"
     ]
    }
   ],
   "source": [
    "ind = np.argsort(sim,axis = 0)[::-1][:10]\n",
    "print(\"Top 10 News Articles similar to new_query are : \\n\")\n",
    "for i in ind:\n",
    "    print(data['Heading'].values[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index of the maximum valued similar document is : \u001b[1m282\u001b[0m\n",
      "Retrieved Document Header is : \u001b[1mStock market eyes Japan recovery\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#Extract Index of Maximum Valued similar document\n",
    "argmax = np.argmax(sim)\n",
    "print(f\"Index of the maximum valued similar document is : \\033[1m{argmax}\\033[0m\")\n",
    "print(f\"Retrieved Document Header is : \\033[1m{data.Heading[argmax]}\\033[0m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_doc(new_query,raw_docs,colname = None): # inputs are new_query,corpus,colname from the dataframe to be used for raw document text\n",
    "    vectorizer = TfidfVectorizer(stop_words = 'english') #convert to Tfidf Vectorizer\n",
    "    vectors = vectorizer.fit_transform(raw_docs[colname]) #preprocess the document, fit the model of tfidf document, transform it\n",
    "    print(f\"The shape of the tfidf matrix : {vectors.shape}\")\n",
    "    print(f\"There are {vectors.shape[0]} number of News Articles having {vectors.shape[1]} unique words in tfidf vectors\")\n",
    "    new_query = [new_query] #tfidf vectorizer accepts on list or an array(doesn't work on raw text)\n",
    "    new_query_vector = vectorizer.transform(new_query) #just transforms/calculates the frequency(of new_query) against the tokens we already have in matrix \n",
    "    new_query_vector\n",
    "    sim = cosine_similarity(X = vectors, Y = new_query_vector)#pairwise cosine similarity\n",
    "    argmax = np.argmax(sim)\n",
    "    print(f\"\\nIndex of the maximum valued similar document is : \\033[1m{argmax}\\033[0m\")\n",
    "    print(f\"Retrieved Document Header is : \\033[1m{data.Heading[argmax]}\\033[0m\")\n",
    "    ind = np.argsort(sim,axis = 0)[::-1][:10] #sorts similarity scores in [::-1] descending order ,[:10] top 10 most similar articles\n",
    "    print(\"\\nTop 10 News Articles similar to new_query are : \\n\")\n",
    "    for i in ind:\n",
    "        print(data.Heading.values[i])#prints the Headings of the top 10 similar articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the tfidf matrix : (2225, 28980)\n",
      "There are 2225 number of News Articles having 28980 unique words in tfidf vectors\n",
      "\n",
      "Index of the maximum valued similar document is : \u001b[1m43\u001b[0m\n",
      "Retrieved Document Header is : \u001b[1mJapan economy slides to recession\u001b[0m\n",
      "\n",
      "Top 10 News Articles similar to new_query are : \n",
      "\n",
      "['Japan economy slides to recession']\n",
      "['Band Aid retains number one spot']\n",
      "['Israeli economy picking up pace']\n",
      "['Singapore growth at 8.1% in 2004']\n",
      "['Singapore growth at 8.1% in 2004']\n",
      "['US box office set for record high']\n",
      "['Australia rates at four year high']\n",
      "[\"'Golden economic period' to end\"]\n",
      "['BBC poll indicates economic gloom']\n",
      "['Business confidence dips in Japan']\n"
     ]
    }
   ],
   "source": [
    "new_query = \"COVID19 hits global economy\"\n",
    "retrieve_doc(new_query,raw_docs=data,colname =  \"Article\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1a98dfdbf5f4dedf5e8d8f4bfd1359a63aa6179b015a1f011f140876f85c4cf3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
